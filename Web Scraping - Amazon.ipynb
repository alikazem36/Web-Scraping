{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNIuxSh4uz87CM+Qzuibdd+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pZoBdiNpjSPW","executionInfo":{"status":"ok","timestamp":1746014327519,"user_tz":-180,"elapsed":21781,"user":{"displayName":"Ali Kazem","userId":"08821755578310878054"}},"outputId":"80ec0ed7-845e-4bbd-b928-87be7cca3361"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting selenium\n","  Downloading selenium-4.31.0-py3-none-any.whl.metadata (7.5 kB)\n","Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.4.0)\n","Collecting trio~=0.17 (from selenium)\n","  Downloading trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n","Collecting trio-websocket~=0.9 (from selenium)\n","  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n","Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.1.31)\n","Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.13.2)\n","Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n","Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (25.3.0)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (2.4.0)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (3.10)\n","Collecting outcome (from trio~=0.17->selenium)\n","  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n","Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n","  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.16.0)\n","Downloading selenium-4.31.0-py3-none-any.whl (9.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trio-0.30.0-py3-none-any.whl (499 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.2/499.2 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n","Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n","Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n","Installing collected packages: wsproto, outcome, trio, trio-websocket, selenium\n","Successfully installed outcome-1.3.0.post0 selenium-4.31.0 trio-0.30.0 trio-websocket-0.12.2 wsproto-1.2.0\n","Collecting msedge-selenium-tools\n","  Downloading msedge_selenium_tools-3.141.4-py3-none-any.whl.metadata (6.6 kB)\n","Collecting selenium==3.141 (from msedge-selenium-tools)\n","  Downloading selenium-3.141.0-py2.py3-none-any.whl.metadata (6.6 kB)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from selenium==3.141->msedge-selenium-tools) (2.4.0)\n","Downloading msedge_selenium_tools-3.141.4-py3-none-any.whl (15 kB)\n","Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m904.6/904.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: selenium, msedge-selenium-tools\n","  Attempting uninstall: selenium\n","    Found existing installation: selenium 4.31.0\n","    Uninstalling selenium-4.31.0:\n","      Successfully uninstalled selenium-4.31.0\n","Successfully installed msedge-selenium-tools-3.141.4 selenium-3.141.0\n","Collecting bs4\n","  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from bs4) (4.13.4)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (2.7)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (4.13.2)\n","Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n","Installing collected packages: bs4\n","Successfully installed bs4-0.0.2\n"]}],"source":["!pip install selenium\n","!pip install msedge-selenium-tools\n","!pip install bs4"]},{"cell_type":"code","source":["!pip install webdriver-manager\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4LaiRobtk7Lc","executionInfo":{"status":"ok","timestamp":1746014593581,"user_tz":-180,"elapsed":2935,"user":{"displayName":"Ali Kazem","userId":"08821755578310878054"}},"outputId":"de3f8f1d-b63c-42ea-c3c3-c8cfa394e5ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: webdriver-manager in /usr/local/lib/python3.11/dist-packages (4.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (2.32.3)\n","Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (1.1.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (24.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver-manager) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver-manager) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver-manager) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver-manager) (2025.1.31)\n"]}]},{"cell_type":"code","source":["pip install -U selenium\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uT1QAAgumIKz","executionInfo":{"status":"ok","timestamp":1746014871379,"user_tz":-180,"elapsed":5450,"user":{"displayName":"Ali Kazem","userId":"08821755578310878054"}},"outputId":"d48c2b39-077b-40cf-dc74-ddef7c1ffeab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (3.141.0)\n","Collecting selenium\n","  Using cached selenium-4.31.0-py3-none-any.whl.metadata (7.5 kB)\n","Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.4.0)\n","Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.30.0)\n","Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.12.2)\n","Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.1.31)\n","Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.13.2)\n","Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n","Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (25.3.0)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (2.4.0)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (3.10)\n","Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n","Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n","Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n","Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.16.0)\n","Using cached selenium-4.31.0-py3-none-any.whl (9.4 MB)\n","Installing collected packages: selenium\n","  Attempting uninstall: selenium\n","    Found existing installation: selenium 3.141.0\n","    Uninstalling selenium-3.141.0:\n","      Successfully uninstalled selenium-3.141.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","msedge-selenium-tools 3.141.4 requires selenium==3.141, but you have selenium 4.31.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed selenium-4.31.0\n"]}]},{"cell_type":"code","source":["driver = webdriver.chrome"],"metadata":{"id":"mtVdzf3OpbzB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["url = 'https://www.amazon.com/'\n","driver.get(url)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":159},"id":"vpsar6A5poVa","executionInfo":{"status":"error","timestamp":1746016002660,"user_tz":-180,"elapsed":17,"user":{"displayName":"Ali Kazem","userId":"08821755578310878054"}},"outputId":"8be9f568-4544-4f1a-eff1-3605bab29155"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"module 'selenium.webdriver.chrome' has no attribute 'get'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-9c1821bdd17a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://www.amazon.com/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: module 'selenium.webdriver.chrome' has no attribute 'get'"]}]},{"cell_type":"code","source":["def my_url(keyword):\n","    temp = 'https://www.amazon.com/s?k={}&crid=2BL65YW8IH6D6&sprefix=phone+cas%2Caps%2C234&ref=nb_sb_noss_2'\n","    keyword = keyword.replace(' ','+')\n","    return temp.format(keyword)\n"],"metadata":{"id":"SlWlW8Dqqpfm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["url = my_url('laptop charger')\n","url"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"hTAvyyUzr-Uw","executionInfo":{"status":"ok","timestamp":1746016499608,"user_tz":-180,"elapsed":10,"user":{"displayName":"Ali Kazem","userId":"08821755578310878054"}},"outputId":"19333a62-eb67-45f0-a1d1-b58fe9496012"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'https://www.amazon.com/s?k=laptop+charger&crid=2BL65YW8IH6D6&sprefix=phone+cas%2Caps%2C234&ref=nb_sb_noss_2'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["url = my_url('kids toys')\n","url"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"0nRkovotsb1a","executionInfo":{"status":"ok","timestamp":1746016529761,"user_tz":-180,"elapsed":64,"user":{"displayName":"Ali Kazem","userId":"08821755578310878054"}},"outputId":"18a1faed-7f4c-4521-903f-6580d25fdbc0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'https://www.amazon.com/s?k=kids+toys&crid=2BL65YW8IH6D6&sprefix=phone+cas%2Caps%2C234&ref=nb_sb_noss_2'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["url = my_url('educational insights')\n","url"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"7KtlNbCbp9KP","executionInfo":{"status":"ok","timestamp":1746166905045,"user_tz":-180,"elapsed":11,"user":{"displayName":"Ali Kazem","userId":"08821755578310878054"}},"outputId":"c16781e6-ef14-4e41-c69a-54ca7295f055"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'https://www.amazon.com/s?k=educational+insights&crid=2BL65YW8IH6D6&sprefix=phone+cas%2Caps%2C234&ref=nb_sb_noss_2'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["!wget -O chromedriver.zip https://chromedriver.storage.googleapis.com/136.0.7326.0/chromedriver_linux64.zip\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FbV-VxUWxy64","executionInfo":{"status":"ok","timestamp":1746168919975,"user_tz":-180,"elapsed":216,"user":{"displayName":"Ali Kazem","userId":"08821755578310878054"}},"outputId":"60342701-f39a-4e16-8d7b-68e3499f5534"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-05-02 06:55:19--  https://chromedriver.storage.googleapis.com/136.0.7326.0/chromedriver_linux64.zip\n","Resolving chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)... 142.250.157.207, 142.251.8.207, 142.251.170.207, ...\n","Connecting to chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)|142.250.157.207|:443... connected.\n","HTTP request sent, awaiting response... 404 Not Found\n","2025-05-02 06:55:20 ERROR 404: Not Found.\n","\n"]}]},{"cell_type":"code","source":["pip install selenium\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"twgZS2ko_wax","executionInfo":{"status":"ok","timestamp":1746172585725,"user_tz":-180,"elapsed":2930,"user":{"displayName":"Ali Kazem","userId":"08821755578310878054"}},"outputId":"b6526850-fa74-4ca5-f130-793d2817041a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.31.0)\n","Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.4.0)\n","Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.30.0)\n","Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.12.2)\n","Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.4.26)\n","Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.13.2)\n","Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n","Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (25.3.0)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (2.4.0)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (3.10)\n","Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n","Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n","Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n","Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.16.0)\n"]}]},{"cell_type":"code","source":["!rm /usr/bin/chromedriver\n"],"metadata":{"id":"y3FWlyCQFuNt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget -q -O /tmp/chromedriver.zip https://storage.googleapis.com/chrome-for-testing-public/136.0.7103.39/linux64/chromedriver-linux64.zip\n"],"metadata":{"id":"94jRgKsVFwZa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip /tmp/chromedriver.zip -d /tmp/\n","!mv /tmp/chromedriver-linux64/chromedriver /usr/bin/chromedriver\n","!chmod +x /usr/bin/chromedriver\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CvdxRfwDFzYV","executionInfo":{"status":"ok","timestamp":1746174164986,"user_tz":-180,"elapsed":528,"user":{"displayName":"Ali Kazem","userId":"08821755578310878054"}},"outputId":"360df74a-859b-481e-f0d1-a995184a440d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /tmp/chromedriver.zip\n","  inflating: /tmp/chromedriver-linux64/LICENSE.chromedriver  \n","  inflating: /tmp/chromedriver-linux64/THIRD_PARTY_NOTICES.chromedriver  \n","  inflating: /tmp/chromedriver-linux64/chromedriver  \n"]}]},{"cell_type":"code","source":["from selenium import webdriver\n","from selenium.webdriver.chrome.service import Service\n","from selenium.webdriver.chrome.options import Options\n","\n","chrome_options = Options()\n","chrome_options.add_argument(\"--headless\")\n","chrome_options.add_argument(\"--disable-gpu\")\n","chrome_options.add_argument(\"--no-sandbox\")\n","chrome_options.add_argument(\"--disable-dev-shm-usage\")\n","\n","driver = webdriver.Chrome(service=Service(\"/usr/bin/chromedriver\"), options=chrome_options)\n","driver.get(\"https://www.google.com\")\n","print(driver.title)\n","driver.quit()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kF5wnuC6F13C","executionInfo":{"status":"ok","timestamp":1746174956013,"user_tz":-180,"elapsed":1677,"user":{"displayName":"Ali Kazem","userId":"08821755578310878054"}},"outputId":"6a75f4ec-3ecf-4bcc-82fa-9b97e7bd99e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Google\n"]}]},{"cell_type":"code","source":["import time\n","import csv\n","from selenium import webdriver\n","from selenium.webdriver.common.by import By\n","from selenium.webdriver.support.ui import WebDriverWait\n","from selenium.webdriver.support import expected_conditions as EC\n","from bs4 import BeautifulSoup\n","from google.colab import files\n","\n","# URL construction function\n","def my_url(keyword):\n","    temp = 'https://www.amazon.com/s?k={}&ref=nb_sb_noss_1'\n","    keyword = keyword.replace(' ', '+')\n","    url = temp.format(keyword)\n","    url += '&page{}'  # Add page query placeholder\n","    return url\n","\n","# Function to extract records from each item\n","def extract_record(obj):\n","    # Debugging: Print the obj to verify structure\n","    print(f\"Processing item: {obj}\")\n","\n","    # Safely extract the <a> tag inside <h2> (checking if it exists)\n","    atag = obj.h2.a if obj.h2 else None\n","    if not atag:\n","        return None  # Skip if there's no <a> tag inside <h2>\n","\n","    description = atag.text.strip() if atag else 'No description'\n","    url = 'https://www.amazon.com' + atag.get('href') if atag else 'No URL'\n","\n","    # Try to get the price, if not found, return None (skip this item)\n","    try:\n","        parent = obj.find('span', 'a-price')\n","        price = parent.find('span', 'a-offscreen').text if parent else 'No price'\n","    except AttributeError:\n","        price = 'No price'\n","\n","    # Try to get the rating and review count, if not found, assign empty values\n","    try:\n","        rate = obj.i.text if obj.i else 'No rating'\n","        counts_review = obj.find('span', {'class': 'a-size-base', 'dir': 'auto'}).text if obj.find('span', {'class': 'a-size-base', 'dir': 'auto'}) else 'No reviews'\n","    except AttributeError:\n","        rate = 'No rating'\n","        counts_review = 'No reviews'\n","\n","    # Try to get the image URL\n","    image = obj.find('img', {'class': 's-image'}).get('src') if obj.find('img', {'class': 's-image'}) else 'No image'\n","\n","    # Return the extracted result as a tuple\n","    result = (description, price, rate, counts_review, url, image)\n","    return result\n","\n","# Main function to perform web scraping\n","def main(keyword):\n","    # Chrome WebDriver options setup\n","    chrome_options = webdriver.ChromeOptions()\n","    chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode (no GUI)\n","    chrome_options.add_argument(\"--no-sandbox\")\n","    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n","\n","    # Start the WebDriver with the specified options\n","    driver = webdriver.Chrome(options=chrome_options)\n","    records = []  # Initialize the records list\n","    url = my_url(keyword)\n","\n","    # Loop through pages (example, 1-3 pages)\n","    for page in range(1, 4):  # Adjust the range to scrape more pages if necessary\n","        driver.get(url.format(page))\n","\n","        # Wait explicitly for search result items to load\n","        WebDriverWait(driver, 10).until(\n","            EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div[data-component-type=\"s-search-result\"]'))\n","        )\n","\n","        soup = BeautifulSoup(driver.page_source, 'html.parser')\n","\n","        # Debugging: Print out the page source to check if data is being loaded\n","        print(f\"Scraping page {page}\")\n","\n","        # Extract search result containers\n","        results = soup.find_all('div', {'data-component-type': 's-search-result'})\n","        if results:\n","            print(f\"Found {len(results)} results on page {page}\")\n","\n","        # Extract records\n","        for item in results:\n","            record = extract_record(item)\n","            if record:\n","                print(f\"Extracted record: {record}\")  # Debugging extracted record\n","                records.append(record)  # Add record to the list\n","\n","    # Save results to CSV\n","    with open('/content/Results.csv', 'w', newline='', encoding='utf-8') as f:\n","        writer = csv.writer(f)\n","        writer.writerow(['Description', 'Price', 'Rating', 'Reviews Count', 'URL', 'Image link'])\n","        writer.writerows(records)\n","\n","    # Trigger download of the CSV file\n","    files.download('/content/Results.csv')\n","\n","    # Quit the driver session after scraping is done\n","    driver.quit()\n","\n","# Run the main function with a keyword\n","main('educational insights')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"15pVQu9riyaFxDsxqkUzRRxaf7j0eJeL7"},"id":"2gjguMqJOU0R","executionInfo":{"status":"ok","timestamp":1746176418859,"user_tz":-180,"elapsed":16222,"user":{"displayName":"Ali Kazem","userId":"08821755578310878054"}},"outputId":"9b6d8381-c0e1-4c0b-c8ba-ac41c755de82"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["chrome_options.add_argument(\"--headless\")\n"],"metadata":{"id":"FShAaon6SnV_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36\")\n"],"metadata":{"id":"-DJzRqBASoXP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import csv\n","from selenium import webdriver\n","from selenium.webdriver.chrome.options import Options\n","from bs4 import BeautifulSoup\n","from google.colab import files\n","import time\n","\n","# Create Amazon URL from keyword\n","def my_url(keyword):\n","    base = 'https://www.amazon.com/s?k={}&page={}'\n","    keyword = keyword.replace(' ', '+')\n","    return base.format(keyword, '{}')\n","\n","# Extract single product record\n","def extract_record(obj):\n","    try:\n","        atag = obj.h2.a\n","        description = atag.text.strip()\n","        url = 'https://www.amazon.com' + atag.get('href')\n","    except:\n","        return None\n","\n","    try:\n","        price = obj.select_one(\"span.a-price > span.a-offscreen\").text.strip()\n","    except:\n","        price = 'No price'\n","\n","    try:\n","        rate = obj.select_one(\"span.a-icon-alt\").text.strip()\n","    except:\n","        rate = 'No rating'\n","\n","    try:\n","        reviews = obj.select_one(\"span.a-size-base.s-underline-text\").text.strip()\n","    except:\n","        reviews = 'No reviews'\n","\n","    try:\n","        image = obj.find('img', {'class': 's-image'}).get('src')\n","    except:\n","        image = 'No image'\n","\n","    return (description, price, rate, reviews, url, image)\n","\n","# Main scraping function\n","def main(keyword):\n","    options = Options()\n","    options.add_argument('--headless')\n","    options.add_argument('--no-sandbox')\n","    options.add_argument('--disable-dev-shm-usage')\n","    driver = webdriver.Chrome(options=options)\n","\n","    records = []\n","    for page in range(1, 4):\n","        print(f\"Scraping page {page}\")\n","        driver.get(my_url(keyword).format(page))\n","        time.sleep(2)  # allow JS to render\n","        soup = BeautifulSoup(driver.page_source, 'html.parser')\n","        results = soup.find_all('div', {'data-component-type': 's-search-result'})\n","        print(f\"Found {len(results)} results on page {page}\")\n","\n","        for item in results:\n","            record = extract_record(item)\n","            if record:\n","                print(f\"Extracted record: {record[0]}\")\n","                records.append(record)\n","\n","    driver.quit()\n","\n","    # Save to CSV\n","    filename = '/content/Results.csv'\n","    with open(filename, 'w', newline='', encoding='utf-8') as f:\n","        writer = csv.writer(f)\n","        writer.writerow(['Description', 'Price', 'Rating', 'Reviews Count', 'URL', 'Image link'])\n","        writer.writerows(records)\n","\n","    files.download(filename)\n","\n","# Run the script\n","main('educational insights')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121},"id":"pX1FzLuwS4VP","executionInfo":{"status":"ok","timestamp":1746177611174,"user_tz":-180,"elapsed":17985,"user":{"displayName":"Ali Kazem","userId":"08821755578310878054"}},"outputId":"d0553b32-4096-463f-b1de-038559305f12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Scraping page 1\n","Found 48 results on page 1\n","Scraping page 2\n","Found 48 results on page 2\n","Scraping page 3\n","Found 48 results on page 3\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_54355f4a-7266-405e-a8d6-e863472b15ee\", \"Results.csv\", 55)"]},"metadata":{}}]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import csv\n","import time\n","import random\n","\n","headers = {\n","    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'\n","}\n","\n","def get_url(keyword, page=1):\n","    return f\"https://www.amazon.com/s?k={keyword.replace(' ', '+')}&page={page}\"\n","\n","def extract_product_info(item):\n","    try:\n","        title = item.h2.text.strip()\n","        link = \"https://www.amazon.com\" + item.h2.a['href']\n","    except AttributeError:\n","        return None\n","\n","    try:\n","        price = item.find('span', 'a-offscreen').text.strip()\n","    except:\n","        price = 'N/A'\n","\n","    try:\n","        rating = item.i.text.strip()\n","    except:\n","        rating = 'N/A'\n","\n","    try:\n","        reviews = item.find('span', {'class': 'a-size-base'}).text.strip()\n","    except:\n","        reviews = 'N/A'\n","\n","    return (title, price, rating, reviews, link)\n","\n","def scrape_amazon(keyword, pages=3):\n","    results = []\n","    for page in range(1, pages + 1):\n","        print(f\"Scraping page {page}\")\n","        url = get_url(keyword, page)\n","        response = requests.get(url, headers=headers)\n","        soup = BeautifulSoup(response.content, 'html.parser')\n","        items = soup.find_all('div', {'data-component-type': 's-search-result'})\n","        print(f\"Found {len(items)} items\")\n","\n","        for item in items:\n","            product = extract_product_info(item)\n","            if product:\n","                results.append(product)\n","\n","        time.sleep(random.uniform(1.5, 3.5))  # Be polite\n","\n","    return results\n","\n","def save_to_csv(data, filename='results.csv'):\n","    with open(filename, 'w', newline='', encoding='utf-8') as f:\n","        writer = csv.writer(f)\n","        writer.writerow(['Title', 'Price', 'Rating', 'Review Count', 'URL'])\n","        writer.writerows(data)\n","    print(f\"Saved {len(data)} items to {filename}\")\n","\n","# Run it\n","keyword = 'educational insights'\n","data = scrape_amazon(keyword)\n","save_to_csv(data)\n"],"metadata":{"id":"gfEGAMC2XzTO","executionInfo":{"status":"ok","timestamp":1746179180687,"user_tz":-180,"elapsed":9757,"user":{"displayName":"Ali Kazem","userId":"08821755578310878054"}},"outputId":"d3522e70-0020-4fdd-f7ed-b865703c9ca5","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Scraping page 1\n","Found 0 items\n","Scraping page 2\n","Found 0 items\n","Scraping page 3\n","Found 0 items\n","Saved 0 items to results.csv\n"]}]},{"cell_type":"code","source":["import csv\n","import time\n","from selenium import webdriver\n","from selenium.webdriver.chrome.service import Service\n","from selenium.webdriver.chrome.options import Options\n","from bs4 import BeautifulSoup\n","\n","def my_url(keyword):\n","    base = 'https://www.amazon.com/s?k={}&page={}'\n","    return base.format(keyword.replace(' ', '+'), '{}')  # placeholder for page number\n","\n","def extract_record(item):\n","    try:\n","        atag = item.h2.a\n","        description = atag.text.strip()\n","        url = 'https://www.amazon.com' + atag.get('href')\n","    except AttributeError:\n","        return None\n","\n","    try:\n","        price = item.find('span', 'a-price').find('span', 'a-offscreen').text\n","    except AttributeError:\n","        price = 'N/A'\n","\n","    try:\n","        rate = item.i.text.strip()\n","    except AttributeError:\n","        rate = 'N/A'\n","\n","    try:\n","        reviews = item.find('span', {'class': 'a-size-base'}).text.strip()\n","    except AttributeError:\n","        reviews = 'N/A'\n","\n","    try:\n","        image = item.find('img', {'class': 's-image'})['src']\n","    except (AttributeError, TypeError):\n","        image = 'N/A'\n","\n","    return (description, price, rate, reviews, url, image)\n","\n","def main(keyword):\n","    options = Options()\n","    options.add_argument(\"--headless\")\n","    options.add_argument(\"--no-sandbox\")\n","    options.add_argument(\"--disable-dev-shm-usage\")\n","\n","    driver = webdriver.Chrome(service=Service(), options=options)\n","    records = []\n","\n","    for page in range(1, 4):  # Scrape pages 1 to 3\n","        print(f\"Scraping page {page}\")\n","        driver.get(my_url(keyword).format(page))\n","        time.sleep(2)\n","        soup = BeautifulSoup(driver.page_source, 'html.parser')\n","        results = soup.find_all('div', {'data-component-type': 's-search-result'})\n","        print(f\"Found {len(results)} results\")\n","\n","        for item in results:\n","            record = extract_record(item)\n","            if record:\n","                records.append(record)\n","\n","    driver.quit()\n","\n","    # Write to CSV\n","    with open('results.csv', 'w', newline='', encoding='utf-8') as f:\n","        writer = csv.writer(f)\n","        writer.writerow(['Description', 'Price', 'Rating', 'Reviews', 'URL', 'Image'])\n","        writer.writerows(records)\n","\n","    print(f\"Scraping completed. {len(records)} products saved to results.csv.\")\n","\n","# Run the scraper\n","main('educational insights')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q7ygayhPc82f","executionInfo":{"status":"ok","timestamp":1746180241630,"user_tz":-180,"elapsed":8064,"user":{"displayName":"Ali Kazem","userId":"08821755578310878054"}},"outputId":"667f91b5-d0b7-48e9-a03b-d7766e4684c1"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["Scraping page 1\n","Found 0 results\n","Scraping page 2\n","Found 0 results\n","Scraping page 3\n","Found 0 results\n","Scraping completed. 0 products saved to results.csv.\n"]}]}]}