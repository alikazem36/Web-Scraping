{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2a84c0f-6619-485d-8c3d-f7bda61b9cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (4.32.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from selenium) (0.30.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from selenium) (2025.4.26)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: requests in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from webdriver-manager) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from trio~=0.17->selenium) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\ali kazem\\appdata\\local\\anaconda32024\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium beautifulsoup4 pandas webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2ea9023-210c-4437-b102-50bc97cb549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# 1. Setup Chrome WebDriver with options\n",
    "options = Options()\n",
    "options.add_argument('--headless')  # Run in background\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# 2. Open Amazon search results\n",
    "search_query = \"educational insights\"\n",
    "url = f\"https://www.amazon.com/s?k={search_query.replace(' ', '+')}\"\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Wait for page to load\n",
    "\n",
    "# 3. Parse the page\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# 4. Extract product data\n",
    "products = soup.find_all(\"div\", {\"data-component-type\": \"s-search-result\"})\n",
    "\n",
    "data = []\n",
    "\n",
    "for product in products:\n",
    "    try:\n",
    "        title_elem = product.h2.a\n",
    "        description = title_elem.text.strip()\n",
    "        product_url = \"https://www.amazon.com\" + title_elem['href']\n",
    "    except:\n",
    "        description = \"\"\n",
    "        product_url = \"\"\n",
    "\n",
    "    try:\n",
    "        price_whole = product.find(\"span\", class_=\"a-price-whole\").text.strip().replace(\",\", \"\")\n",
    "        price_frac = product.find(\"span\", class_=\"a-price-fraction\").text.strip()\n",
    "        price = f\"${price_whole}.{price_frac}\"\n",
    "    except:\n",
    "        price = \"\"\n",
    "\n",
    "    try:\n",
    "        rating = product.find(\"span\", class_=\"a-icon-alt\").text.strip()\n",
    "    except:\n",
    "        rating = \"\"\n",
    "\n",
    "    try:\n",
    "        review_count = product.find(\"span\", {\"class\": \"a-size-base\"}).text.strip()\n",
    "    except:\n",
    "        review_count = \"\"\n",
    "\n",
    "    try:\n",
    "        image = product.find(\"img\", class_=\"s-image\")['src']\n",
    "    except:\n",
    "        image = \"\"\n",
    "\n",
    "    data.append({\n",
    "        \"Description\": description,\n",
    "        \"Price\": price,\n",
    "        \"Rating\": rating,\n",
    "        \"Reviews Count\": review_count,\n",
    "        \"URL\": product_url,\n",
    "        \"Image link\": image\n",
    "    })\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88cdaed9-5f7c-4956-bd20-c3a9250b9657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews Count</th>\n",
       "      <th>URL</th>\n",
       "      <th>Image link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>$53..19</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "      <td>Products highlighted as 'Overall Pick' are:</td>\n",
       "      <td></td>\n",
       "      <td>https://m.media-amazon.com/images/I/71XC1NcMMy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>$18..86</td>\n",
       "      <td>4.7 out of 5 stars</td>\n",
       "      <td>54</td>\n",
       "      <td></td>\n",
       "      <td>https://m.media-amazon.com/images/I/71S9YuOg53...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>$31..99</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "      <td>298</td>\n",
       "      <td></td>\n",
       "      <td>https://m.media-amazon.com/images/I/71OdEPAfiY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>$43..49</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>263</td>\n",
       "      <td></td>\n",
       "      <td>https://m.media-amazon.com/images/I/81pYVc69sx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>$9..97</td>\n",
       "      <td>4.7 out of 5 stars</td>\n",
       "      <td>31,155</td>\n",
       "      <td></td>\n",
       "      <td>https://m.media-amazon.com/images/I/71v68G+xVA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description    Price              Rating  \\\n",
       "0              $53..19  4.6 out of 5 stars   \n",
       "1              $18..86  4.7 out of 5 stars   \n",
       "2              $31..99  4.6 out of 5 stars   \n",
       "3              $43..49  4.5 out of 5 stars   \n",
       "4               $9..97  4.7 out of 5 stars   \n",
       "\n",
       "                                 Reviews Count URL  \\\n",
       "0  Products highlighted as 'Overall Pick' are:       \n",
       "1                                           54       \n",
       "2                                          298       \n",
       "3                                          263       \n",
       "4                                       31,155       \n",
       "\n",
       "                                          Image link  \n",
       "0  https://m.media-amazon.com/images/I/71XC1NcMMy...  \n",
       "1  https://m.media-amazon.com/images/I/71S9YuOg53...  \n",
       "2  https://m.media-amazon.com/images/I/71OdEPAfiY...  \n",
       "3  https://m.media-amazon.com/images/I/81pYVc69sx...  \n",
       "4  https://m.media-amazon.com/images/I/71v68G+xVA...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Export to CSV\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"amazon_educational_insights.csv\", index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4bbd1a-6d1b-4a16-bb73-8f943cb6b88c",
   "metadata": {},
   "source": [
    "# Now Scraping the page sorting by the newest arrivals (1 page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d160608-f57f-4528-81a8-0f8817396712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 52 items to amazon_educational_insights2.csv\n",
      "You can find it here: C:\\Users\\Ali Kazem\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1) Configure headless Chrome\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_argument(\n",
    "    \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    ")\n",
    "\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# 2) Build URL with sort=newest\n",
    "search = \"educational insights\"\n",
    "base_url = \"https://www.amazon.com/s\"\n",
    "params = f\"?k={search.replace(' ', '+')}&s=date-desc-rank\"\n",
    "full_url = base_url + params\n",
    "\n",
    "driver.get(full_url)\n",
    "\n",
    "# 3) Wait for the results container to load\n",
    "try:\n",
    "    WebDriverWait(driver, 15).until(\n",
    "        EC.presence_of_all_elements_located(\n",
    "            (By.CSS_SELECTOR, 'div[data-component-type=\"s-search-result\"]')\n",
    "        )\n",
    "    )\n",
    "except Exception:\n",
    "    print(\"Timed out waiting for page to load\")\n",
    "    driver.quit()\n",
    "    raise\n",
    "\n",
    "# 4) Parse page source\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "items = soup.select('div[data-component-type=\"s-search-result\"]')\n",
    "\n",
    "data = []\n",
    "for item in items:\n",
    "    # Description & URL\n",
    "    a = item.h2.a\n",
    "    title = a.get_text(strip=True) if a else \"\"\n",
    "    url = \"https://www.amazon.com\" + a[\"href\"] if a and a.has_attr(\"href\") else \"\"\n",
    "\n",
    "    # Price\n",
    "    price_whole = item.select_one(\"span.a-price-whole\")\n",
    "    price_frac  = item.select_one(\"span.a-price-fraction\")\n",
    "    if price_whole and price_frac:\n",
    "        price = f\"${price_whole.text.strip()}.{price_frac.text.strip()}\"\n",
    "    else:\n",
    "        price = \"\"\n",
    "\n",
    "    # Rating\n",
    "    rate = item.select_one(\"span.a-icon-alt\")\n",
    "    rating = rate.text.strip() if rate else \"\"\n",
    "\n",
    "    # Reviews count\n",
    "    rev = item.select_one(\"span.a-size-base\")\n",
    "    reviews = rev.text.strip() if rev else \"\"\n",
    "\n",
    "    # Image link\n",
    "    img = item.select_one(\"img.s-image\")\n",
    "    img_url = img[\"src\"] if img and img.has_attr(\"src\") else \"\"\n",
    "\n",
    "    data.append({\n",
    "        \"Description\": title,\n",
    "        \"Price\": price,\n",
    "        \"Rating\": rating,\n",
    "        \"Reviews Count\": reviews,\n",
    "        \"URL\": url,\n",
    "        \"Image link\": img_url\n",
    "    })\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# 5) Export to CSV\n",
    "df = pd.DataFrame(data)\n",
    "out_file = \"amazon_educational_insights2.csv\"\n",
    "df.to_csv(out_file, index=False)\n",
    "print(f\"Saved {len(df)} items to {out_file}\")\n",
    "print(\"You can find it here:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2f4970-593b-4598-878a-9b6233d01d7c",
   "metadata": {},
   "source": [
    "# Now Scraping the page sorting by the newest arrivals (3 pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9ef692a-e476-496e-baee-000ff5105775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1: Found 52 items.\n",
      "Page 2: Found 52 items.\n",
      "Page 3: Found 52 items.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Setup Chrome options\n",
    "options = Options()\n",
    "options.add_argument('--headless')  # comment this out if you want to see the browser\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_argument(\"window-size=1920,1080\")\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\")\n",
    "\n",
    "# Initialize the driver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Base Amazon URL\n",
    "base_url = \"https://www.amazon.com/s\"\n",
    "search_term = \"educational insights\"\n",
    "params = f\"?k={search_term.replace(' ', '+')}&s=date-desc-rank\"  # sort by newest arrivals\n",
    "\n",
    "data = []\n",
    "\n",
    "# Scrape first 3 pages\n",
    "for page_num in range(1, 4):\n",
    "    paginated_url = f\"{base_url}{params}&page={page_num}\"\n",
    "    driver.get(paginated_url)\n",
    "\n",
    "    try:\n",
    "        WebDriverWait(driver, 15).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div[data-component-type=\"s-search-result\"]'))\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Timeout or error on page {page_num}: {e}\")\n",
    "        continue\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    items = soup.select('div[data-component-type=\"s-search-result\"]')\n",
    "\n",
    "    print(f\"Page {page_num}: Found {len(items)} items.\")\n",
    "\n",
    "    for item in items:\n",
    "        a = item.h2.a\n",
    "        title = a.get_text(strip=True) if a else \"\"\n",
    "        url = \"https://www.amazon.com\" + a[\"href\"] if a and a.has_attr(\"href\") else \"\"\n",
    "\n",
    "        price_whole = item.select_one(\"span.a-price-whole\")\n",
    "        price_frac = item.select_one(\"span.a-price-fraction\")\n",
    "        if price_whole and price_frac:\n",
    "            price = f\"${price_whole.text.strip()}.{price_frac.text.strip()}\"\n",
    "        else:\n",
    "            price = \"\"\n",
    "\n",
    "        rate = item.select_one(\"span.a-icon-alt\")\n",
    "        rating = rate.text.strip() if rate else \"\"\n",
    "\n",
    "        rev = item.select_one(\"span.a-size-base\")\n",
    "        reviews = rev.text.strip() if rev else \"\"\n",
    "\n",
    "        img = item.select_one(\"img.s-image\")\n",
    "        img_url = img[\"src\"] if img and img.has_attr(\"src\") else \"\"\n",
    "\n",
    "        data.append({\n",
    "            \"Description\": title,\n",
    "            \"Price\": price,\n",
    "            \"Rating\": rating,\n",
    "            \"Reviews Count\": reviews,\n",
    "            \"URL\": url,\n",
    "            \"Image link\": img_url\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd04a21-bd8a-4b8d-84fd-4e5e65096b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"amazon_educational_insights3.csv\", index=False)\n",
    "print(\"Saved to amazon_educational_insights.csv\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec80a9b-7869-4bc3-8caf-ab11c03dcb83",
   "metadata": {},
   "source": [
    "# Export Images into Excel File (Visible as Embedded Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "681a54b3-6d56-48ca-84ee-db01b098ba33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlsxwriter\n",
      "  Downloading XlsxWriter-3.2.3-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading XlsxWriter-3.2.3-py3-none-any.whl (169 kB)\n",
      "Installing collected packages: xlsxwriter\n",
      "Successfully installed xlsxwriter-3.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ffb9ac0-24c0-482e-b005-f8c6b594c718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to amazon_products_with_images.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import xlsxwriter\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv(\"amazon_educational_insights.csv\")\n",
    "\n",
    "# Create a new workbook and worksheet\n",
    "workbook = xlsxwriter.Workbook(\"amazon_products_with_images.xlsx\")\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "# Write headers\n",
    "for col_num, header in enumerate(df.columns):\n",
    "    worksheet.write(0, col_num, header)\n",
    "\n",
    "# Write data with image preview\n",
    "for row_num, row in df.iterrows():\n",
    "    for col_num, value in enumerate(row):\n",
    "        if df.columns[col_num] == \"Image link\":\n",
    "            try:\n",
    "                response = requests.get(value, timeout=10)\n",
    "                image_data = BytesIO(response.content)\n",
    "                worksheet.insert_image(row_num + 1, col_num, value, {\"image_data\": image_data, \"x_scale\": 0.3, \"y_scale\": 0.3})\n",
    "            except Exception as e:\n",
    "                worksheet.write(row_num + 1, col_num, \"Image failed\")\n",
    "        else:\n",
    "            # Convert NaN/inf to safe text\n",
    "            if pd.isna(value) or isinstance(value, float) and not pd.isfinite(value):\n",
    "                worksheet.write(row_num + 1, col_num, \"\")\n",
    "            else:\n",
    "                worksheet.write(row_num + 1, col_num, str(value))\n",
    "\n",
    "workbook.close()\n",
    "print(\"Saved to amazon_products_with_images.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400fa47d-c7ea-4de4-86e7-4c26e9058f0f",
   "metadata": {},
   "source": [
    "# Add Data in the description column and additional column for Item link (Didn't work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ce97485-6e9a-4ab7-bc0d-cfca6a1872a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping complete. Data saved to 'amazon_educational_insights.csv'.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Set up headless Chrome\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "base_url = \"https://www.amazon.com/s?k=educational+insights&i=toys-and-games&rh=n%3A166164011&dc&qid=1700000000&rnid=2941120011&ref=sr_pg_{}\"\n",
    "\n",
    "# Lists to store data\n",
    "descriptions = []\n",
    "prices = []\n",
    "ratings = []\n",
    "review_counts = []\n",
    "image_links = []\n",
    "sub_descriptions = []\n",
    "item_links = []\n",
    "\n",
    "# Loop through first 3 pages\n",
    "for page in range(1, 4):\n",
    "    url = base_url.format(page)\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    items = soup.find_all(\"div\", {\"data-component-type\": \"s-search-result\"})\n",
    "\n",
    "    for item in items:\n",
    "        # Description (short title)\n",
    "        desc_tag = item.h2\n",
    "        desc = desc_tag.text.strip() if desc_tag else \"\"\n",
    "        descriptions.append(desc)\n",
    "\n",
    "        # Price\n",
    "        price_whole = item.find(\"span\", class_=\"a-price-whole\")\n",
    "        price_fraction = item.find(\"span\", class_=\"a-price-fraction\")\n",
    "        if price_whole and price_fraction:\n",
    "            price = f\"{price_whole.text.strip()}.{price_fraction.text.strip()}\"\n",
    "        else:\n",
    "            price = \"\"\n",
    "        prices.append(price)\n",
    "\n",
    "        # Rating\n",
    "        rating_tag = item.find(\"span\", class_=\"a-icon-alt\")\n",
    "        rating = rating_tag.text.strip().split(\" out\")[0] if rating_tag else \"\"\n",
    "        ratings.append(rating)\n",
    "\n",
    "        # Reviews count\n",
    "        review_tag = item.find(\"span\", {\"class\": \"a-size-base\", \"dir\": \"auto\"})\n",
    "        reviews = review_tag.text.strip() if review_tag else \"\"\n",
    "        review_counts.append(reviews)\n",
    "\n",
    "        # Image link\n",
    "        image_tag = item.find(\"img\", class_=\"s-image\")\n",
    "        image = image_tag[\"src\"] if image_tag else \"\"\n",
    "        image_links.append(image)\n",
    "\n",
    "        # Sub Description\n",
    "        sub_desc = \"\"\n",
    "        h2_tag = item.find(\"h2\")\n",
    "        if h2_tag:\n",
    "            span = h2_tag.find(\"span\")\n",
    "            if span:\n",
    "                sub_desc = span.text.strip()\n",
    "        sub_descriptions.append(sub_desc)\n",
    "\n",
    "        # Item link\n",
    "        item_link = \"\"\n",
    "        if h2_tag:\n",
    "            a_tag = h2_tag.find(\"a\")\n",
    "            if a_tag and a_tag.get(\"href\"):\n",
    "                item_link = \"https://www.amazon.com\" + a_tag[\"href\"]\n",
    "        item_links.append(item_link)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Save to CSV\n",
    "df = pd.DataFrame({\n",
    "    \"Description\": descriptions,\n",
    "    \"Price\": prices,\n",
    "    \"Rating\": ratings,\n",
    "    \"Reviews Count\": review_counts,\n",
    "    \"Image link\": image_links,\n",
    "    \"Sub Description\": sub_descriptions,\n",
    "    \"Item link\": item_links\n",
    "})\n",
    "\n",
    "df.to_csv(\"amazon_educational_insights2.csv\", index=False)\n",
    "print(\"Scraping complete. Data saved to 'amazon_educational_insights.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2813c2ad-49d4-42ea-87da-1e4c3722c1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
